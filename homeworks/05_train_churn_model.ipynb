{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "In this homework, we will use Bank credit scoring dataset from [here](https://www.kaggle.com/datasets/kapturovalexander/bank-credit-scoring/data).\n",
    "\n",
    "> **Note**: sometimes your answer doesn't match one of the options exactly. That's fine. \n",
    "Select the option that's closest to your solution.\n",
    "\n",
    "> **Note**: we recommend using python 3.10 in this homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "* Install Pipenv\n",
    "* What's the version of pipenv you installed?\n",
    "* Use `--version` to find out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pipenv in /home/gitpod/.pyenv/versions/3.11.5/lib/python3.11/site-packages (2023.9.8)\n",
      "Requirement already satisfied: certifi in /home/gitpod/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from pipenv) (2023.7.22)\n",
      "Requirement already satisfied: setuptools>=67 in /home/gitpod/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from pipenv) (68.2.2)\n",
      "Requirement already satisfied: virtualenv>=20.24.2 in /home/gitpod/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from pipenv) (20.24.5)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in /home/gitpod/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from virtualenv>=20.24.2->pipenv) (0.3.7)\n",
      "Requirement already satisfied: filelock<4,>=3.12.2 in /home/gitpod/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from virtualenv>=20.24.2->pipenv) (3.12.4)\n",
      "Requirement already satisfied: platformdirs<4,>=3.9.1 in /home/gitpod/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from virtualenv>=20.24.2->pipenv) (3.10.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipenv, version 2023.9.8\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "pip install pipenv\n",
    "pipenv --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pipenv version is 2023.9.8.\n"
     ]
    }
   ],
   "source": [
    "print(\"The pipenv version is 2023.9.8.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "* Use Pipenv to install Scikit-Learn version 1.3.1\n",
    "* What's the first hash for scikit-learn you get in Pipfile.lock?\n",
    "\n",
    "> **Note**: you should create an empty folder for homework\n",
    "and do it there. \n",
    "\n",
    "\n",
    "## Models\n",
    "\n",
    "We've prepared a dictionary vectorizer and a model.\n",
    "\n",
    "They were trained (roughly) using this code:\n",
    "\n",
    "```python\n",
    "features = ['job','duration', 'poutcome']\n",
    "dicts = df[features].to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X = dv.fit_transform(dicts)\n",
    "\n",
    "model = LogisticRegression().fit(X, y)\n",
    "```\n",
    "\n",
    "> **Note**: You don't need to train the model. This code is just for your reference.\n",
    "\n",
    "And then saved with Pickle. Download them:\n",
    "\n",
    "* [DictVectorizer](https://github.com/DataTalksClub/machine-learning-zoomcamp/tree/master/cohorts/2023/05-deployment/homework/dv.bin?raw=true)\n",
    "* [LogisticRegression](https://github.com/DataTalksClub/machine-learning-zoomcamp/tree/master/cohorts/2023/05-deployment/homework/model1.bin?raw=true)\n",
    "\n",
    "With `wget`:\n",
    "\n",
    "```bash\n",
    "PREFIX=https://raw.githubusercontent.com/DataTalksClub/machine-learning-zoomcamp/master/cohorts/2023/05-deployment/homework\n",
    "wget $PREFIX/model1.bin\n",
    "wget $PREFIX/dv.bin\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32mInstalling scikit-learn\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "\u001b[?25lResolving scikit-learn\u001b[33m...\u001b[0m\n",
      "\u001b[2K✔ Installation Succeeded\n",
      "\u001b[2K\u001b[32m⠋\u001b[0m Installing scikit-learn...\n",
      "\u001b[1A\u001b[2K\u001b[1mInstalling dependencies from Pipfile.lock \u001b[0m\u001b[1m(\u001b[0m\u001b[1m5bcbaf\u001b[0m\u001b[1m)\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "To activate this project's virtualenv, run \u001b[33mpipenv shell\u001b[0m.\n",
      "Alternatively, run a command inside the virtualenv with \u001b[33mpipenv run\u001b[0m.\n"
     ]
    }
   ],
   "source": [
    "!pipenv install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first Pipfile.lock has is: {'sha256': '274a40143df6722a398a09f94cdbe356f1669d80b40c4059aa5e7fb0bc5bcbaf'}.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('Pipfile.lock', 'rb') as pipfile:\n",
    "    json_file = json.load(pipfile)\n",
    "    first_hash = json_file['_meta']['hash']\n",
    "    print(f\"The first Pipfile.lock has is: {first_hash}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘homework_05’: File exists\n",
      "--2023-10-16 22:04:12--  https://raw.githubusercontent.com/DataTalksClub/machine-learning-zoomcamp/master/cohorts/2023/05-deployment/homework/model1.bin\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 842 [application/octet-stream]\n",
      "Saving to: ‘homework_05/model1.bin.1’\n",
      "\n",
      "model1.bin.1        100%[===================>]     842  --.-KB/s    in 0s      \n",
      "\n",
      "2023-10-16 22:04:12 (97.2 MB/s) - ‘homework_05/model1.bin.1’ saved [842/842]\n",
      "\n",
      "--2023-10-16 22:04:12--  https://raw.githubusercontent.com/DataTalksClub/machine-learning-zoomcamp/master/cohorts/2023/05-deployment/homework/dv.bin\n",
      "Reusing existing connection to raw.githubusercontent.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 560 [application/octet-stream]\n",
      "Saving to: ‘homework_05/dv.bin.1’\n",
      "\n",
      "dv.bin.1            100%[===================>]     560  --.-KB/s    in 0s      \n",
      "\n",
      "2023-10-16 22:04:12 (72.7 MB/s) - ‘homework_05/dv.bin.1’ saved [560/560]\n",
      "\n",
      "FINISHED --2023-10-16 22:04:12--\n",
      "Total wall clock time: 0.3s\n",
      "Downloaded: 2 files, 1.4K in 0s (85.7 MB/s)\n"
     ]
    }
   ],
   "source": [
    "!mkdir homework_05\n",
    "PREFIX=\"https://raw.githubusercontent.com/DataTalksClub/machine-learning-zoomcamp/master/cohorts/2023/05-deployment/homework\"\n",
    "!wget $PREFIX/model1.bin $PREFIX/dv.bin -P homework_05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Let's use these models!\n",
    "\n",
    "* Write a script for loading these models with pickle\n",
    "* Score this client:\n",
    "\n",
    "```json\n",
    "{\"job\": \"retired\", \"duration\": 445, \"poutcome\": \"success\"}\n",
    "```\n",
    "\n",
    "What's the probability that this client will get a credit? \n",
    "\n",
    "* 0.162\n",
    "* 0.392\n",
    "* 0.652\n",
    "* 0.902\n",
    "\n",
    "If you're getting errors when unpickling the files, check their checksum:\n",
    "\n",
    "```bash\n",
    "$ md5sum model1.bin dv.bin\n",
    "8ebfdf20010cfc7f545c43e3b52fc8a1  model1.bin\n",
    "924b496a89148b422c74a62dbc92a4fb  dv.bin\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model_file = \"homework_05/model1.bin\"\n",
    "dv_file = \"homework_05/dv.bin\"\n",
    "\n",
    "def read_pickle(file_path):\n",
    "    with open(file_path, \"rb\") as f_in:\n",
    "        py_object = pickle.load(f_in)\n",
    "    return py_object\n",
    "\n",
    "model = read_pickle(model_file)\n",
    "dv = read_pickle(dv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = {\"job\": \"retired\", \"duration\": 445, \"poutcome\": \"success\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(customer):\n",
    "\n",
    "    X = dv.transform([customer])\n",
    "    y_pred = model.predict_proba(X)[0, 1]\n",
    "    get_credit = y_pred >= 0.5\n",
    "\n",
    "    result = {\"credit_probability\": float(y_pred), \"get_credit\": bool(get_credit)}\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'credit_probability': 0.9019309332297606, 'get_credit': True}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_analysis = predict(customer)\n",
    "credit_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of this customer get credit is 0.902\n"
     ]
    }
   ],
   "source": [
    "print(f\"The probability of this customer get credit is {credit_analysis['credit_probability']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Now let's serve this model as a web service\n",
    "\n",
    "* Install Flask and gunicorn (or waitress, if you're on Windows)\n",
    "* Write Flask code for serving the model\n",
    "* Now score this client using `requests`:\n",
    "\n",
    "```python\n",
    "url = \"YOUR_URL\"\n",
    "client = {\"job\": \"unknown\", \"duration\": 270, \"poutcome\": \"failure\"}\n",
    "requests.post(url, json=client).json()\n",
    "```\n",
    "\n",
    "What's the probability that this client will get a credit?\n",
    "\n",
    "* 0.140\n",
    "* 0.440\n",
    "* 0.645\n",
    "* 0.845"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The api code is in predict.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'credit_probability': 0.13968947052356817, 'get_credit': False}\n"
     ]
    }
   ],
   "source": [
    "url = 'http://localhost:9696/predict'\n",
    "client_id = 'alpha-123'\n",
    "client = {\"job\": \"unknown\", \"duration\": 270, \"poutcome\": \"failure\"}\n",
    "response = requests.post(url, json=client).json()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The client alpha-123 will not get credit, the probability is 0.140.\n"
     ]
    }
   ],
   "source": [
    "if response['get_credit'] == True:\n",
    "    print(f'The client {client_id} will get credit, the probability is {response[\"credit_probability\"]:.3f}.')\n",
    "else:\n",
    "    print(f'The client {client_id} will not get credit, the probability is {response[\"credit_probability\"]:.3f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker\n",
    "\n",
    "Install [Docker](https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/05-deployment/06-docker.md). \n",
    "We will use it for the next two questions.\n",
    "\n",
    "For these questions, we prepared a base image: `svizor/zoomcamp-model:3.10.12-slim`. \n",
    "You'll need to use it (see Question 5 for an example).\n",
    "\n",
    "This image is based on `python:3.10.12-slim` and has a logistic regression model \n",
    "(a different one) as well a dictionary vectorizer inside. \n",
    "\n",
    "This is how the Dockerfile for this image looks like:\n",
    "\n",
    "```docker \n",
    "FROM python:3.10.12-slim\n",
    "WORKDIR /app\n",
    "COPY [\"model2.bin\", \"dv.bin\", \"./\"]\n",
    "```\n",
    "\n",
    "We already built it and then pushed it to [`svizor/zoomcamp-model:3.10.12-slim`](https://hub.docker.com/r/svizor/zoomcamp-model).\n",
    "\n",
    "> **Note**: You don't need to build this docker image, it's just for your reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "Download the base image `svizor/zoomcamp-model:3.10.12-slim`. You can easily make it by using [docker pull](https://docs.docker.com/engine/reference/commandline/pull/) command.\n",
    "\n",
    "So what's the size of this base image?\n",
    "\n",
    "* 47 MB\n",
    "* 147 MB\n",
    "* 374 MB\n",
    "* 574 MB\n",
    "\n",
    "You can get this information when running `docker images` - it'll be in the \"SIZE\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image base size is 147MB.\n"
     ]
    }
   ],
   "source": [
    "print(\"The image base size is 147MB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dockerfile\n",
    "\n",
    "Now create your own Dockerfile based on the image we prepared.\n",
    "\n",
    "It should start like that:\n",
    "\n",
    "```docker\n",
    "FROM svizor/zoomcamp-model:3.10.12-slim\n",
    "# add your stuff here\n",
    "```\n",
    "\n",
    "Now complete it:\n",
    "\n",
    "* Install all the dependencies form the Pipenv file\n",
    "* Copy your Flask script\n",
    "* Run it with Gunicorn \n",
    "\n",
    "After that, you can build your docker image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Let's run your docker container!\n",
    "\n",
    "After running it, score this client once again:\n",
    "\n",
    "```python\n",
    "url = \"YOUR_URL\"\n",
    "client = {\"job\": \"retired\", \"duration\": 445, \"poutcome\": \"success\"}\n",
    "requests.post(url, json=client).json()\n",
    "```\n",
    "\n",
    "What's the probability that this client will get a credit now?\n",
    "\n",
    "* 0.168\n",
    "* 0.530\n",
    "* 0.730\n",
    "* 0.968"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'http://localhost:9696/predict'\n",
    "\n",
    "client = {\"job\": \"retired\", \"duration\": 445, \"poutcome\": \"success\"}\n",
    "response = requests.post(url, json=client).json()\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
